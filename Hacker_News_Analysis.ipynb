{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "## Introduction\n",
    "\n",
    "In this project we will be analysing a dataset of submissions to the popular technology site Hacker News (https://news.ycombinator.com/).\n",
    "\n",
    "Hacker News is a site started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") are voted and commented upon, similar to reddit. Hacker News is extremely popular in technology and startup circles, and posts that make it to the top of Hacker News' listings can get hundreds of thousands of visitors as a result.\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either Ask HN or Show HN. Users submit Ask HN posts to ask the Hacker News community a specific question. An example being:\n",
    "\n",
    " - Ask HN: How to improve my personal website?\n",
    "\n",
    "Likewise, users submit Show HN posts to show the Hacker News community a project, product, or just generally something interesting. For example:\n",
    "\n",
    " - Show HN: Something pointless I made\n",
    "\n",
    "We will be comparing these two types of posts, to determine the following:\n",
    "\n",
    " - Do Ask HN or Show HN receive more comments on average?\n",
    " - Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "We will begin by importing the libraries we need and importing the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n\n\n[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
    }
   ],
   "source": [
    "import csv\n",
    "opened_file = open(\"hacker_news.csv\", encoding= \"utf8\")\n",
    "read_file = csv.reader(opened_file)\n",
    "hn = list(read_file)\n",
    "# header only\n",
    "header = hn[0]\n",
    "# data\n",
    "hn = hn[1:]\n",
    "# peak at the headrer and data\n",
    "print(header)\n",
    "print(\"\\n\")\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are only concerned with post titles that begin with either Ask HN or Show HN, so we will create a new lists of lists containing only those.\n",
    "To find the posts that begin with either Ask HN or Show HN, we'll use the string method `startswith`. Given a string object, say, string1, we can check if it starts with, say, dq by inspecting the output of the object string1.startswith('dq'). If string1 starts with dq, it will return True, otherwise it will return False. \n",
    "Note, that this is case sensitive. We can specify lowercase for example, using the `lower` method, which returns a lowercase version of the starting string.\n",
    "\n",
    "**Let's use these methods to separate posts beginning with Ask HN and Show HN (and case variations) into two different lists next.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53'], ['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17'], ['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57'], ['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48'], ['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']]\nNumber of ask posts is: 9,139\n\n\n[['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36'], ['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01'], ['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44'], ['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17'], ['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']]\nNumber of show posts is: 10,158\n\n\n[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\nNumber of other posts is: 273,822\n"
    }
   ],
   "source": [
    "# create empty lists\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    if title.lower().startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.lower().startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "# peak at ask_posts\n",
    "print(ask_posts[:5])\n",
    "print(\"Number of ask posts is: {posts:,}\".format(posts = len(ask_posts)))\n",
    "print(\"\\n\")\n",
    "# peak at show_posts\n",
    "print(show_posts[:5])\n",
    "print(\"Number of show posts is: {posts:,}\".format(posts = len(show_posts)))\n",
    "print(\"\\n\")\n",
    "# peak at other_posts\n",
    "print(other_posts[:5])\n",
    "print(\"Number of other posts is: {posts:,}\".format(posts = len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of comments in the ask_posts set = 94,986\nAverage number of comments for Ask HN = 10.39\n"
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "\n",
    "for row in ask_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_ask_comments += num_comments\n",
    "\n",
    "print(\"Total number of comments in the ask_posts set = {comments:,}\".format(comments = total_ask_comments)) # total number of comments in the ask_posts set\n",
    "\n",
    "# to determine the average, divide by length of ask_posts (number of posts with 'ask hn')\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "\n",
    "print(\"Average number of comments for Ask HN = {avg_posts:.2f}\".format(avg_posts = avg_ask_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now will will do the same for show posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total number of comments in the show_posts set = 49,633\nAverage number of comments for Show HN = 4.89\n"
    }
   ],
   "source": [
    "total_show_comments = 0\n",
    "\n",
    "for row in show_posts:\n",
    "    num_comments = int(row[4])\n",
    "    total_show_comments += num_comments\n",
    "\n",
    "print(\"Total number of comments in the show_posts set = {comments:,}\".format(comments = total_show_comments)) # total number of comments in the show_posts set\n",
    "\n",
    "# to determine the average, divide by length of show_posts (number of posts with 'show hn')\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"Average number of comments for Show HN = {avg_posts:.2f}\".format(avg_posts = avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results above indicate that in this dataset ask posts received almost twice as many comments as show posts, as well as having on average, more than twice the number of comments per post. This is interesting, given within this dataset (which covers a period between 2015 and 2016), there were about 1,000 more show posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we have determined that ask posts receive more comments than show posts, for our remaining analysis we will focus on these alone.\n",
    "\n",
    "Next, we will determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "\n",
    " - Calculate the amount of ask posts created in each hour of the day, along with the number of comments received.\n",
    " - Calculate the average number of comments ask posts receive by hour created.\n",
    "\n",
    "First, we'll tackle the first step — calculating the amount of ask posts and comments by hour created. We'll use the datetime module to work with the data in the created_at column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Extract from the result list showing the date/time of the post and the number of comments:\n[['9/26/2016 2:53', 7], ['9/26/2016 1:17', 3], ['9/25/2016 22:57', 0], ['9/25/2016 22:48', 3], ['9/25/2016 21:50', 2]]\n\n\nOur dictionary of counts by hour (number of ask hn posts per hour):\n{'02': 269, '01': 282, '22': 383, '21': 518, '19': 552, '17': 587, '15': 646, '14': 513, '13': 444, '11': 312, '10': 282, '09': 222, '07': 226, '03': 271, '23': 343, '20': 510, '16': 579, '08': 257, '00': 301, '18': 614, '12': 342, '04': 243, '06': 234, '05': 209}\n\n\nOur dictionary of comments by hour (number of comments posted per hour for ask hn posts):\n{'02': 2996, '01': 2089, '22': 3372, '21': 4500, '19': 3954, '17': 5547, '15': 18525, '14': 4972, '13': 7245, '11': 2797, '10': 3013, '09': 1477, '07': 1585, '03': 2154, '23': 2297, '20': 4462, '16': 4466, '08': 2362, '00': 2277, '18': 4877, '12': 4234, '04': 2360, '06': 1587, '05': 1838}\n\n\n"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for row in ask_posts:\n",
    "    created_at = row[6]\n",
    "    num_comments = int(row[4])\n",
    "    result_list.append([created_at, num_comments]) # append both elements to the result_list, creating a list of lists\n",
    "\n",
    "print(\"Extract from the result list showing the date/time of the post and the number of comments:\")\n",
    "print(result_list[:5])\n",
    "print(\"\\n\")\n",
    "\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    date_time = dt.datetime.strptime(row[0], \"%m/%d/%Y %H:%M\")\n",
    "    hour = date_time.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]\n",
    "\n",
    "print(\"Our dictionary of counts by hour (number of ask hn posts per hour):\")\n",
    "print(counts_by_hour)\n",
    "print(\"\\n\")\n",
    "print(\"Our dictionary of comments by hour (number of comments posted per hour for ask hn posts):\")\n",
    "print(comments_by_hour)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have two dictionaries showing count(posts) by hour and number of comments by hour, we can calculate the average number of comments for posts created during each hour of the day. Therefore identifying which hour of the day an ask hn post will likely generate most comments. \n",
    "\n",
    "The following is a very basic example of the logic we will follow to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[['apple', 20], ['banana', 40], ['orange', 60]]\n"
    }
   ],
   "source": [
    "# lets use the following dictionary:\n",
    "sample_dict = {\n",
    "                'apple': 2, \n",
    "                'banana': 4, \n",
    "                'orange': 6\n",
    "               }\n",
    "# Suppose we wanted to multiply each of the values by ten and return the results as a list of lists. We can use the following code:\n",
    "\n",
    "fruits = []\n",
    "\n",
    "for fruit in sample_dict:\n",
    "    fruits.append([fruit, 10 * sample_dict[fruit]])\n",
    "\n",
    "# which gives:\n",
    "print(fruits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the example above, we:\n",
    "\n",
    " - Initialized an empty list (of lists) and assigned it to fruits.\n",
    " - Iterated over the keys of sample_dict and appended to fruits a list whose:\n",
    "    - First element is the key from sample_dict.\n",
    "    - Second element is the value corresponding to that key multiplied by ten.\n",
    "\n",
    "**Let's use this format to create a list of lists containing the hours during which posts were created and the average number of comments those posts received.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Following list of lists displays the hour of the day, followed by the average number of comments an ask hn post gets in that hour\n\n\n[['02', 11.14], ['01', 7.41], ['22', 8.8], ['21', 8.69], ['19', 7.16], ['17', 9.45], ['15', 28.68], ['14', 9.69], ['13', 16.32], ['11', 8.96], ['10', 10.68], ['09', 6.65], ['07', 7.01], ['03', 7.95], ['23', 6.7], ['20', 8.75], ['16', 7.71], ['08', 9.19], ['00', 7.56], ['18', 7.94], ['12', 12.38], ['04', 9.71], ['06', 6.78], ['05', 8.79]]\n"
    }
   ],
   "source": [
    "# result will be a list of lists in which the first element is the hour and the second element is the average number of comments per post.\n",
    "\n",
    "avg_by_hour = []\n",
    "\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour, round(comments_by_hour[hour] / counts_by_hour[hour], 2)]) # extract total number of comments by hour and divide by extracted total number of posts per hour\n",
    "\n",
    "print(\"Following list of lists displays the hour of the day, followed by the average number of comments an ask hn post gets in that hour\")\n",
    "print(\"\\n\")\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we now have the results we need, this format makes it hard to identify the hours with the highest values. Let's finish by sorting the list of lists and printing the five highest values in a format that's easier to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "list of hour and average number of comments with swapped columns:\n\n\n[[11.14, '02'], [7.41, '01'], [8.8, '22'], [8.69, '21'], [7.16, '19'], [9.45, '17'], [28.68, '15'], [9.69, '14'], [16.32, '13'], [8.96, '11'], [10.68, '10'], [6.65, '09'], [7.01, '07'], [7.95, '03'], [6.7, '23'], [8.75, '20'], [7.71, '16'], [9.19, '08'], [7.56, '00'], [7.94, '18'], [12.38, '12'], [9.71, '04'], [6.78, '06'], [8.79, '05']]\n\n\nSorted (desc):\n[[28.68, '15'], [16.32, '13'], [12.38, '12'], [11.14, '02'], [10.68, '10'], [9.71, '04'], [9.69, '14'], [9.45, '17'], [9.19, '08'], [8.96, '11'], [8.8, '22'], [8.79, '05'], [8.75, '20'], [8.69, '21'], [7.95, '03'], [7.94, '18'], [7.71, '16'], [7.56, '00'], [7.41, '01'], [7.16, '19'], [7.01, '07'], [6.78, '06'], [6.7, '23'], [6.65, '09']]\n\n\nTop 5 Hours for Ask Posts Comments\n15:00: 28.68 average comments per post\n13:00: 16.32 average comments per post\n12:00: 12.38 average comments per post\n02:00: 11.14 average comments per post\n10:00: 10.68 average comments per post\n"
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "\n",
    "print(\"list of hour and average number of comments with swapped columns:\")\n",
    "print(\"\\n\")\n",
    "print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse= True)\n",
    "print(\"\\n\")\n",
    "print(\"Sorted (desc):\")\n",
    "print(sorted_swap)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(row[1], \"%H\")\n",
    "    hour = hour.strftime(\"%H\")\n",
    "    average = row[0]\n",
    "    template = \"{hour}:00: {average:.2f} average comments per post\".format(hour = hour, average = average)\n",
    "    print(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**\n",
    "\n",
    "**On average, the most number of comments relating to Ask HN are posted at 3pm.** Therefore, if we were to recommend a time to post an Ask HN with the aim of receiving maximum number of comments, it would be then!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}